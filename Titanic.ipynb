{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "nD4MQPubtaBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Basic Random Forest Classifier"
      ]
    },
    {
      "metadata": {
        "id": "Q4aBhl0vxHeO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, install OpenML:\n",
        "\n",
        "\n",
        "\n",
        "> \"*The Open Machine Learning project is an inclusive movement to build an open, organized, online ecosystem for machine learning*\""
      ]
    },
    {
      "metadata": {
        "id": "t_-jvWcfgyBl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install openml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7GF3H9vMxoz5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, import `RandomForestClassifier` from SKLearn. Also import the `train_test_split` function from SKLearn, as well as `openml`."
      ]
    },
    {
      "metadata": {
        "id": "MszFQSunx6WY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import openml as oml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0i2GZ7Ux9yi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then, get the Titanic dataset from OpenML, lod it, get the data, and split it into training and testing data."
      ]
    },
    {
      "metadata": {
        "id": "tsJmA3vex-BZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = oml.datasets.get_dataset(40704)\n",
        "\n",
        "x, y, attribute_names = dataset.get_data(\n",
        "    target=dataset.default_target_attribute,\n",
        "    return_attribute_names=True,\n",
        ")\n",
        "\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oz95k9FPyIqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, train the classifier."
      ]
    },
    {
      "metadata": {
        "id": "CSoo8lWzyLce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "914f0d25-8fef-4a34-a332-23e0f64d8f3b"
      },
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=100,min_samples_split=10)\n",
        "clf.fit(xtrain,ytrain)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=10,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "JuIgj7QKyNMZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, test the accuracy!"
      ]
    },
    {
      "metadata": {
        "id": "C5iq-Xg9_1Re",
        "colab_type": "code",
        "outputId": "6c80317a-f7e8-48bd-b933-dee29b2c8d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pred = clf.predict(xtest)\n",
        "count=0\n",
        "for i in range(len(ytest)):\n",
        "  if(pred[i]==ytest[i]):\n",
        "    count+=1\n",
        "    \n",
        "print((count/len(ytest))*100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70.13574660633483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8Xz6hf8tfA1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TPOT Genetic Alogrithm"
      ]
    },
    {
      "metadata": {
        "id": "rbXJq9BzxTBt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "FIrst, install TPOT,  which generates a pipline by using a genetic alogrithm."
      ]
    },
    {
      "metadata": {
        "id": "4Sp_2RSntl-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tpot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ol_oWNx0yUHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next import the `TPOTClassifier` from TPOT. We will also need OpenML and `train_test_split`."
      ]
    },
    {
      "metadata": {
        "id": "674EQ6U2ydn5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tpot import TPOTClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import openml as oml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1XJVIgHyhMM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then, get the Titanic dataset from OpenML, lod it, get the data, and split it into training and testing data."
      ]
    },
    {
      "metadata": {
        "id": "-Ki-g2ITynjD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = oml.datasets.get_dataset(40704)\n",
        "\n",
        "x, y, attribute_names = dataset.get_data(\n",
        "    target=dataset.default_target_attribute,\n",
        "    return_attribute_names=True,\n",
        ")\n",
        "\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3iOoUwDytT7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, start up the genetic algorithm."
      ]
    },
    {
      "metadata": {
        "id": "cOjY8kf5yyIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "91bb191b-04d5-45fc-b174-3437401b421e"
      },
      "cell_type": "code",
      "source": [
        "clf = TPOTClassifier(generations=5, verbosity=2)\n",
        "clf.fit(xtrain,ytrain)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  33%|███▎      | 200/600 [01:28<03:39,  1.83pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: 0.7989898989898989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  50%|█████     | 300/600 [02:26<02:18,  2.17pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 2 - Current best internal CV score: 0.7989898989898989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  67%|██████▋   | 400/600 [03:30<01:44,  1.91pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 3 - Current best internal CV score: 0.7989898989898989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Progress:  83%|████████▎ | 500/600 [05:13<01:35,  1.04pipeline/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 4 - Current best internal CV score: 0.7989898989898989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 5 - Current best internal CV score: 0.7989898989898989\n",
            "\n",
            "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=1.0, max_depth=4, max_features=0.3, min_samples_leaf=16, min_samples_split=12, n_estimators=100, subsample=0.7500000000000001)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "        disable_update_check=False, early_stop=None, generations=5,\n",
              "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
              "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
              "        periodic_checkpoint_folder=None, population_size=100,\n",
              "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
              "        verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "69_5Pljbyz3k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, test the accuracy!"
      ]
    },
    {
      "metadata": {
        "id": "yjJtyIX1tjsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29fad17e-0be7-4c07-903e-1d86d3bbee4b"
      },
      "cell_type": "code",
      "source": [
        "pred = clf.predict(xtest)\n",
        "count=0\n",
        "for i in range(len(ytest)):\n",
        "  if(pred[i]==ytest[i]):\n",
        "    count+=1\n",
        "    \n",
        "print((count/len(ytest))*100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70.13574660633483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WT-YuIhDv2C0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generated Model"
      ]
    },
    {
      "metadata": {
        "id": "-zJHa_-2y4hr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the model generated by the genetic algorithm."
      ]
    },
    {
      "metadata": {
        "id": "wD622sQyzCDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6c6469c-1632-4b72-850c-515bd2c72d7f"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "tpot = GradientBoostingClassifier( 2learning_rate=1.0, max_depth=4, max_features=0.3, min_samples_leaf=16, min_samples_split=12, n_estimators=100, subsample=0.7500000000000001)\n",
        "tpot.fit(xtrain,ytrain)\n",
        "\n",
        "pred = tpot.predict(xtest)\n",
        "count=0\n",
        "for i in range(len(ytest)):\n",
        "  if(pred[i]==ytest[i]):\n",
        "    count+=1\n",
        "    \n",
        "print((count/len(ytest))*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70.13574660633483\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}